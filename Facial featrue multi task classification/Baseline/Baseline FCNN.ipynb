{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T01:53:27.049387Z",
     "start_time": "2025-03-31T00:26:14.404303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CelebA\n",
    "from torchvision.transforms.v2 import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    ColorJitter,\n",
    "    RandomHorizontalFlip,\n",
    "    ToImage,\n",
    "    ToDtype,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# --- Config ---\n",
    "DTYPE = torch.float32\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 50\n",
    "PATIENCE = 3\n",
    "INPUT_SHAPE = (3, 64, 64)\n",
    "SAVE_PATH = \"./checkpoints/best_fcnn_model.pt\"\n",
    "os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)\n",
    "\n",
    "# --- Device ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Transforms ---\n",
    "train_transform = Compose([\n",
    "    Resize((64, 64)),\n",
    "    ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "    RandomHorizontalFlip(),\n",
    "    ToImage(),\n",
    "    ToDtype(dtype=DTYPE, scale=True),\n",
    "])\n",
    "\n",
    "normal_transform = Compose([\n",
    "    Resize((64, 64)),\n",
    "    ToImage(),\n",
    "    ToDtype(DTYPE, scale=True),\n",
    "])\n",
    "\n",
    "# --- Dataset path ---\n",
    "data_path = \"C:/Users/manju/Desktop/ECSE 552/Project\"  # update if needed\n",
    "\n",
    "# --- Datasets & Loaders ---\n",
    "train_set = CelebA(data_path, split=\"train\", target_type=\"attr\", transform=train_transform, download=False)\n",
    "val_set = CelebA(data_path, split=\"valid\", target_type=\"attr\", transform=normal_transform, download=False)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
   ],
   "id": "c8719462675178a3",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# --- Model ---\n",
    "class FCNN(nn.Module):\n",
    "    def __init__(self, input_shape=(3, 64, 64), num_classes=40):\n",
    "        super(FCNN, self).__init__()\n",
    "        c, h, w = input_shape\n",
    "        input_dim = c * h * w\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes),\n",
    "            nn.Sigmoid()  # for multi-label classification\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# --- Initialize model on GPU ---\n",
    "model = FCNN(input_shape=INPUT_SHAPE).to(device)\n",
    "criterion = nn.BCELoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ],
   "id": "c3adcf3f84786810"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "\n",
    "# --- Training Helpers ---\n",
    "def transform_batch_labels(batch):\n",
    "    images, labels = batch\n",
    "    images = images.to(device, non_blocking=True)\n",
    "    labels = labels.to(device, dtype=torch.float32, non_blocking=True)\n",
    "    return images, labels\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in tqdm(loader, desc=\"Training\"):\n",
    "        images, labels = transform_batch_labels(batch)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Validation\"):\n",
    "            images, labels = transform_batch_labels(batch)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "# --- Training with Early Stopping ---\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss = evaluate(model, val_loader, criterion)\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), SAVE_PATH)\n",
    "        print(f\"✅ Best model saved to {SAVE_PATH}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"⏸️ No improvement for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(\"🛑 Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# --- Load best model ---\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n",
    "print(\"🔁 Loaded best model weights from disk.\")\n"
   ],
   "id": "d8a88b4351565556"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T05:24:32.145463Z",
     "start_time": "2025-03-28T05:23:58.501249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            pred_binary = (probs > 0.5).float()\n",
    "\n",
    "            all_preds.append(pred_binary.cpu().numpy())\n",
    "            all_labels.append(y.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    return all_preds, all_labels\n",
    "\n",
    "test_set = CelebA(data_path, split=\"test\", target_type=\"attr\", transform=normal_transform, download=False)\n",
    "test_loader = DataLoader(test_set, batch_size=32)\n",
    "all_preds, all_labels = evaluate(model, test_loader, device)"
   ],
   "id": "d0fd44bdf173755a",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T05:33:29.570389Z",
     "start_time": "2025-03-28T05:33:29.563838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure preds and labels are numpy arrays\n",
    "# all_preds: binary predictions (0/1), shape: [N, 40]\n",
    "# all_labels: ground truth labels (0/1), shape: [N, 40]\n",
    "\n",
    "# Element-wise correctness\n",
    "correct_matrix = (all_preds == all_labels).astype(np.float32)\n",
    "\n",
    "# Per-attribute accuracy\n",
    "attribute_accuracy = correct_matrix.mean(axis=0)  # shape: [40]\n",
    "\n",
    "# Overall accuracy (average across all attributes and samples)\n",
    "overall_accuracy = correct_matrix.mean()\n",
    "\n",
    "print(f\"Overall accuracy: {overall_accuracy:.4f}\")\n"
   ],
   "id": "2bbb878102dac150",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T05:08:35.866730Z",
     "start_time": "2025-03-28T05:08:35.853437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate per-attribute accuracy\n",
    "correct_matrix = (all_preds == all_labels).astype(np.float32)\n",
    "attribute_accuracy = correct_matrix.mean(axis=0)  # shape: (40,)\n",
    "\n",
    "# Print each attribute's accuracy\n",
    "for i, attr in enumerate(ATTRIBUTES):\n",
    "    print(f\"{attr:25s}: {attribute_accuracy[i]:.4f}\")\n"
   ],
   "id": "684b8470a896ae5",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T05:34:13.683493Z",
     "start_time": "2025-03-28T05:34:13.373107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def save_preds_labels_to_csv(all_preds, all_labels, filename=\"results.csv\", attributes=None):\n",
    "    \"\"\"\n",
    "    Save predictions and labels to a CSV file side-by-side.\n",
    "    If attribute names are given, use them as column headers.\n",
    "    \"\"\"\n",
    "    # Make sure arrays are numpy\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Prefix column names\n",
    "    if attributes is None:\n",
    "        attributes = [f\"attr_{i}\" for i in range(all_preds.shape[1])]\n",
    "\n",
    "    pred_cols = [f\"pred_{attr}\" for attr in attributes]\n",
    "    label_cols = [f\"true_{attr}\" for attr in attributes]\n",
    "\n",
    "    df_preds = pd.DataFrame(all_preds, columns=pred_cols)\n",
    "    df_labels = pd.DataFrame(all_labels, columns=label_cols)\n",
    "\n",
    "    df = pd.concat([df_preds, df_labels], axis=1)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"✅ Saved predictions and labels to {filename}\")\n",
    "\n",
    "\n",
    "\n",
    "save_preds_labels_to_csv(all_preds, all_labels, filename=\"fcnn_test_results.csv\", attributes=ATTRIBUTES)\n"
   ],
   "id": "d8625b1ca36bf7d9",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "97603a309b4693f0",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
