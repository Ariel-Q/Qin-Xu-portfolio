{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T01:16:22.916546Z",
     "start_time": "2025-04-06T01:15:18.877386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import torch\n",
    "from torchvision.datasets import CelebA\n",
    "from torchvision.transforms.v2 import (\n",
    "    CenterCrop,\n",
    "    ColorJitter,\n",
    "    Compose,\n",
    "    RandomHorizontalFlip,\n",
    "    ToDtype,\n",
    "    ToImage,\n",
    ")\n",
    "\n",
    "# Initial datatype of the images, will be converted by autocast later\n",
    "DTYPE = torch.float32\n",
    "\n",
    "## change the path to the path where the data is stored\n",
    "# path = \"C:/Users/modi/Desktop/ecse 552/Project/Facial-Attribute-Recognition-main/model/data\"\n",
    "path = \"C:/Users/manju/Desktop/ECSE 552/Project\"\n",
    "train_transform = Compose(\n",
    "    [\n",
    "        # RandomRotation(15, interpolation=InterpolationMode.BILINEAR),\n",
    "        CenterCrop(178),\n",
    "        ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToImage(),\n",
    "        ToDtype(dtype=DTYPE, scale=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "normal_transform = Compose([CenterCrop(178), ToImage(), ToDtype(DTYPE, scale=True)])\n",
    "\n",
    "train = CelebA(path, \"train\",  transform=train_transform)\n",
    "test = CelebA(path, \"test\", transform=normal_transform)\n",
    "val = CelebA(path, \"valid\", transform=normal_transform)\n",
    "import random\n",
    "import textwrap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ATTRIBUTES = train.attr_names[:-1]\n",
    "\n",
    "print(f\"Number of pictures: {len(train)}\")\n",
    "\n",
    "print(f\"Number of attributes: {len(ATTRIBUTES)}\")\n",
    "\n",
    "print(f\"Attribute names: {', '.join(ATTRIBUTES)}\")\n",
    "\n",
    "shape = train[0][0].shape\n",
    "print(f\"Resolution: {shape[1]}x{shape[2]}\")\n"
   ],
   "id": "bd29fa1609896794",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pictures: 162770\n",
      "Number of attributes: 40\n",
      "Attribute names: 5_o_Clock_Shadow, Arched_Eyebrows, Attractive, Bags_Under_Eyes, Bald, Bangs, Big_Lips, Big_Nose, Black_Hair, Blond_Hair, Blurry, Brown_Hair, Bushy_Eyebrows, Chubby, Double_Chin, Eyeglasses, Goatee, Gray_Hair, Heavy_Makeup, High_Cheekbones, Male, Mouth_Slightly_Open, Mustache, Narrow_Eyes, No_Beard, Oval_Face, Pale_Skin, Pointy_Nose, Receding_Hairline, Rosy_Cheeks, Sideburns, Smiling, Straight_Hair, Wavy_Hair, Wearing_Earrings, Wearing_Hat, Wearing_Lipstick, Wearing_Necklace, Wearing_Necktie, Young\n",
      "Resolution: 178x178\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T00:27:22.717444Z",
     "start_time": "2025-03-31T00:27:22.714019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ],
   "id": "4b79d4a66766354",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T00:56:41.068253Z",
     "start_time": "2025-03-31T00:56:41.055778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# --- CNN MODEL ---\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=3, stride=2),  # [3, 178, 178] -> [8, 88, 88]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                          # [8, 88, 88] -> [8, 44, 44]\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(8 * 44 * 44, num_classes),\n",
    "            nn.Sigmoid(),  # for multilabel\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "# --- Transforming labels ---\n",
    "def transform_batch_labels(batch):\n",
    "    images, labels = batch\n",
    "    return images.to(device), labels.float().to(device)  # ‚Üê no transform_y\n",
    "\n",
    "\n",
    "# --- Setup ---\n",
    "num_classes = 40\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN(num_classes = 40).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=64, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# --- Training Function ---\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in tqdm(loader, desc=\"Training\"):\n",
    "        images, labels = transform_batch_labels(batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "# --- Validation Function ---\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Validation\"):\n",
    "            images, labels = transform_batch_labels(batch)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n"
   ],
   "id": "31c497fe1a3bc285",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T02:41:06.134988Z",
     "start_time": "2025-03-31T00:56:41.533461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Detect GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üöÄ Using device: {device}\")\n",
    "\n",
    "# Folder to save model\n",
    "save_dir = \"./checkpoints\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "model_path = os.path.join(save_dir, \"best_model.pt\")\n",
    "\n",
    "# --- Early Stopping Config ---\n",
    "patience = 3\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs_without_improvement = 0\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"‚úÖ Validation loss improved. Model saved to {model_path}\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"‚è∏Ô∏è No improvement for {epochs_without_improvement} epoch(s).\")\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(\"üõë Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# --- Load model with proper device map ---\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "print(\"üîÅ Loaded best model weights and moved to GPU.\")\n"
   ],
   "id": "a0b4a0073b0138de",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T02:52:40.564922Z",
     "start_time": "2025-03-31T02:52:40.558582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_and_collect(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Evaluating\"):\n",
    "            images, labels = transform_batch_labels(batch)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            pred_binary = (outputs > 0.5).float()\n",
    "            all_preds.append(pred_binary.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = running_loss / len(loader)\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    print(f\"\\n‚úÖ Evaluation completed ‚Äî Avg Loss: {avg_loss:.4f}\")\n",
    "    return all_preds, all_labels\n",
    "\n"
   ],
   "id": "10333781ed3d7dc3",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T02:52:41.505370Z",
     "start_time": "2025-03-31T02:52:41.500850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üöÄ Using device: {device}\")"
   ],
   "id": "f2e19aeb54b878de",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T02:52:42.141122Z",
     "start_time": "2025-03-31T02:52:42.137282Z"
    }
   },
   "cell_type": "code",
   "source": "test_loader = DataLoader(test, batch_size=64, shuffle=False, num_workers=2)",
   "id": "e9e40ee39002e15",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T02:52:59.321395Z",
     "start_time": "2025-03-31T02:52:42.776471Z"
    }
   },
   "cell_type": "code",
   "source": "all_preds, all_labels = evaluate_and_collect(model, test_loader, criterion = nn.BCELoss(), device = device)",
   "id": "d8a88b4351565556",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T02:52:59.329248Z",
     "start_time": "2025-03-31T02:52:59.322401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure preds and labels are numpy arrays\n",
    "# all_preds: binary predictions (0/1), shape: [N, 40]\n",
    "# all_labels: ground truth labels (0/1), shape: [N, 40]\n",
    "\n",
    "# Element-wise correctness\n",
    "correct_matrix = (all_preds == all_labels).astype(np.float32)\n",
    "\n",
    "# Per-attribute accuracy\n",
    "attribute_accuracy = correct_matrix.mean(axis=0)  # shape: [40]\n",
    "\n",
    "# Overall accuracy (average across all attributes and samples)\n",
    "overall_accuracy = correct_matrix.mean()\n",
    "\n",
    "print(f\"Overall accuracy: {overall_accuracy:.4f}\")\n"
   ],
   "id": "8ce494f8024228ae",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T02:52:59.336254Z",
     "start_time": "2025-03-31T02:52:59.330253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "correct_matrix = (all_preds == all_labels).astype(np.float32)\n",
    "attribute_accuracy = correct_matrix.mean(axis=0)  # shape: (40,)\n",
    "\n",
    "# Print each attribute's accuracy\n",
    "for i, attr in enumerate(ATTRIBUTES):\n",
    "    print(f\"{attr:25s}: {attribute_accuracy[i]:.4f}\")"
   ],
   "id": "76d2e58b06cf2ec5",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T02:53:00.226431Z",
     "start_time": "2025-03-31T02:52:59.336759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def save_preds_labels_to_csv(all_preds, all_labels, filename=\"results.csv\", attributes=None):\n",
    "    \"\"\"\n",
    "    Save predictions and labels to a CSV file side-by-side.\n",
    "    If attribute names are given, use them as column headers.\n",
    "    \"\"\"\n",
    "    # Make sure arrays are numpy\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Prefix column names\n",
    "    if attributes is None:\n",
    "        attributes = [f\"attr_{i}\" for i in range(all_preds.shape[1])]\n",
    "\n",
    "    pred_cols = [f\"pred_{attr}\" for attr in attributes]\n",
    "    label_cols = [f\"true_{attr}\" for attr in attributes]\n",
    "\n",
    "    df_preds = pd.DataFrame(all_preds, columns=pred_cols)\n",
    "    df_labels = pd.DataFrame(all_labels, columns=label_cols)\n",
    "\n",
    "    df = pd.concat([df_preds, df_labels], axis=1)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"‚úÖ Saved predictions and labels to {filename}\")\n"
   ],
   "id": "354b054ea8b074f3",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T03:15:09.147501Z",
     "start_time": "2025-03-31T03:15:08.689360Z"
    }
   },
   "cell_type": "code",
   "source": "save_preds_labels_to_csv(all_preds, all_labels, filename=\"cnn_basic_results_1.csv\", attributes=ATTRIBUTES)\n",
   "id": "8aa5bed4a45962e7",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T01:11:43.155711Z",
     "start_time": "2025-03-29T01:11:42.116270Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "26716bb9b18d4e32",
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "a4d09bfabbdb851a",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
