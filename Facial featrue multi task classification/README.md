# ECSE552 Final Project â€” Multi-Label Facial Attribute Classification

This project investigates multi-label facial attribute classification using deep neural networks. We implement and compare two architectures:

- ğŸŸ¨ A **CNN-based model** using a pretrained ResNet-50 backbone and a lightweight MLP head.
- ğŸŸ¦ A **Transformer-based model** using EfficientFormerV2 with a region-wise grouped classification head.

Both models are trained and evaluated on the CelebA dataset. Metrics include accuracy, precision, recall, and macro-F1 score. We also analyze label noise and attribute difficulty by comparing performance across objective and subjective attribute subsets.

---

## ğŸ“ Project Structure

```
ECSE552_FINAL_PROJECT/
â”œâ”€â”€ ResNet-50/                        # CNN-based model
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ main_hengyi.ipynb
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ cnn_multilabel_model.py
â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â””â”€â”€ celeb_A_dataset.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”‚   â””â”€â”€ eval_utils.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ list_attr_celeba.txt
â”‚   â”‚   â”œâ”€â”€ img_align_celeba/
â”‚   â”‚   â””â”€â”€ train.csv / val.csv / celeba_multilabel.csv
â”‚   â””â”€â”€ checkpoints/

â”œâ”€â”€ Transformer/                          # Transformer-based model
â”‚   â”œâ”€â”€ main_Modi.ipynb
â”‚   â”œâ”€â”€ mymodel.py
â”‚   â”œâ”€â”€ efficientformer_v2.py
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ trained_tf.pth

â”œâ”€â”€ Plots/                         

â”œâ”€â”€ Baseline/                        
â”‚   â”œâ”€â”€ Baseline CNN.ipynb
â”‚   â”œâ”€â”€ Baseline FCNN.ipynb

â”œâ”€â”€ Baseline/                          
â”‚   â”œâ”€â”€ Baseline CNN.ipynb
â”‚   â”œâ”€â”€ Baseline FCNN.ipynb


â”œâ”€â”€ requirements.txt
â””â”€â”€ Evaluation and Comparison.ipynb
â””â”€â”€ report.pdf
â””â”€â”€ Plots
â””â”€â”€ Results
```

---

## ğŸ§  Model Overview

### ğŸŸ¨ CNN-Based Model (ResNet-50)

- ResNet-50 pretrained on ImageNet
- FC layer replaced with `nn.Identity()`
- Classification head:
  ```python
  nn.Sequential(
      nn.Linear(2048, 512),
      nn.ReLU(),
      nn.Dropout(0.3),
      nn.Linear(512, 40)
  )
  ```

### ğŸŸ¦ Transformer-Based Model (EfficientFormerV2)

- EfficientFormerV2-S2 variant from `timm`
- Last-stage feature map fed to grouped classification head
- Attributes are grouped by region (e.g., hair, eyes, mouth)
- Output: 40 logits â†’ `Sigmoid` activation

---

## ğŸ§ª Training & Evaluation

- Dataset: CelebA, using standard train / val / test split
- Loss: `BCEWithLogitsLoss`
- Optimizer: Adam
- Batch Size: 32
- Evaluation metrics:
  - Accuracy, Precision, Recall
  - Macro-F1 (main metric)

Both models apply data augmentations:
```python
transforms.Compose([
    transforms.CenterCrop(178),
    transforms.ColorJitter(0.1, 0.1, 0.1, 0.05),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor()
])
```

---

## ğŸš€ How to Run

### 1. Install dependencies:
```bash
pip install -r requirements.txt
```

### 2. Prepare CelebA dataset:
Download the following from [CelebA official site](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html):
- `img_align_celeba/`
- `list_attr_celeba.txt`

Then run preprocessing:
```bash
python ResNet-50/utils/preprocess.py
```

### 3. Train CNN model:
```bash
cd ResNet-50/
python train.py
```

### 4. Run Transformer (EfficientFormer) model:
```bash
cd Transformer/
jupyter notebook main.ipynb
```

---

## ğŸ“Š Output & Evaluation

- Best checkpoints saved to `checkpoints/`
- Final evaluation results in `cnn_test_results.csv` / notebook cells
- Figures for attribute performance, confusion, and noise sensitivity in report and notebooks

---

## ğŸ‘¨â€ğŸ“ Authors

- Ariel Xu
- Hengyi Yin  
- Modi Fan 
Course: ECSE552 â€” Deep Learning for Engineering  
McGill University â€” Winter 2025

---

## ğŸ“„ License

This repository is intended for academic use only.
