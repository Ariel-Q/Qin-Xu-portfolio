{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T01:05:23.260380Z",
     "start_time": "2024-06-07T01:05:22.648434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sweetviz as sv\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "9a1290a2d7e690b3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T01:05:23.266744Z",
     "start_time": "2024-06-07T01:05:23.261385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ],
   "id": "f4fbac9c88f3e372",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = reduce_mem_usage(pd.read_csv('credit_card_transactions-ibm_v2.csv'))",
   "id": "698659c10768c934",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "report = sv.analyze(df)\n",
    "report.show_html('Sweetviz_Report.html')"
   ],
   "id": "b2a96be55a689112",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "file:///C:/Users/manju/OneDrive%20-%20McGill%20University/Desktop/scientificProject/Sweetviz_Report.html",
   "id": "d7aa226b7c3997f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "card = reduce_mem_usage(pd.read_csv('sd254_cards.csv'))\n",
    "user = reduce_mem_usage(pd.read_csv('sd254_users.csv'))"
   ],
   "id": "59b224f67521047b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Data preprocessing for user\n",
    "user[\"User\"] = range(2000) # create User ID to join with 'card'\n",
    "## Remove the dollar signs\n",
    "user[\"Yearly Income - Person\"] = user[\"Yearly Income - Person\"].str.replace(\"$\", \"\").astype(float)\n",
    "user[\"Total Debt\"] = user[\"Total Debt\"].str.replace(\"$\", \"\").astype(float)\n",
    "user[\"User_Location_Income\"] = user[\"Per Capita Income - Zipcode\"].str.replace(\"$\", \"\").astype(float)\n",
    "## Define new variable indicating users retirement status\n",
    "user['Retired'] = 'No'\n",
    "user.loc[user['Current Age'] > user['Retirement Age'], 'Retired'] = 'Yes'\n",
    "## Define variables that are the ratio of their income, debt, and the income level at their location\n",
    "user['Person_Location_Income_ratio'] = user[\"Yearly Income - Person\"]/(user[\"User_Location_Income\"])\n",
    "user['Person_Income_toDebt'] = user[\"Yearly Income - Person\"]/(user[\"Total Debt\"])\n",
    "user['Location_Income_toDebt'] = user[\"User_Location_Income\"]/(user[\"Total Debt\"])"
   ],
   "id": "5c3924cad1bb459d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Select variables use for further analysis\n",
    "user = user[['User', 'Gender', \"Current Age\", \"Retirement Age\" ,\"Retired\", \"User_Location_Income\", 'Yearly Income - Person', \"Total Debt\", \"Num Credit Cards\", 'Person_Location_Income_ratio','Person_Income_toDebt','Location_Income_toDebt']]"
   ],
   "id": "f85967f8aceeea4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Data preprocessing for cards\n",
    "card[\"User_Card\"] = card['User'].astype(str) + '_' + card['CARD INDEX'].astype(str) ## Create card id to join with transaction data\n",
    "## Remove the dollor sign\n",
    "card[\"Credit Limit\"] = card[\"Credit Limit\"].str.replace(\"$\", \"\").astype(float)\n",
    "card['Expire_Year'] = pd.to_datetime(card['Expires'], format='%m/%Y').dt.year\n",
    "card['Expire_Month'] = pd.to_datetime(card['Expires'], format='%m/%Y').dt.month\n",
    "card['Open_Year'] = pd.to_datetime(card['Acct Open Date'], format='%m/%Y').dt.year\n",
    "card['Open_Month'] = pd.to_datetime(card['Acct Open Date'], format='%m/%Y').dt.month\n"
   ],
   "id": "82516e689d826a17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Select variables of interest\n",
    "card = card[[\"User_Card\", \"User\", 'Card Brand', \"Card Type\", \"Credit Limit\"]]"
   ],
   "id": "4832ed326924e37f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Left join with 'user'\n",
    "card = card.merge(user, on='User', how='left')\n",
    "card = card.drop(columns=['User'])\n"
   ],
   "id": "6d7275b04bf90260",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "t = pd.read_csv('User0_credit_card_transactions.csv')",
   "id": "9de61e290379debf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Create the 'User_Card' index to join with crdit card information\n",
    "df[\"User_Card\"] = df['User'].astype(str) + '_' + df['Card'].astype(str)\n",
    "# Remove the dollar sign\n",
    "df[\"Amount\"] = df[\"Amount\"].str.replace(\"$\", \"\").astype(float)"
   ],
   "id": "d9adcd90503454a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Keep data with positive amount\n",
    "df = df[df['Amount'] > 0]"
   ],
   "id": "49e567a75fcd404c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df.merge(card, on='User_Card', how='left')",
   "id": "ae53a5658eca07c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Remove columns that will not be used\n",
    "df = df.drop(columns=['User', 'Card', 'User_Card', \"Errors?\", \"Merchant Name\", \"Merchant State\", \"Zip\", 'MCC'])"
   ],
   "id": "6c1266b5da0fe4d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = df.drop(columns=['User', 'Card', 'User_Card'])\n",
    "df.head()"
   ],
   "id": "9412dac19cf8999c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['Merchant State']=df['Merchant State'].fillna('unknown')\n",
    "df['Zip']=df['Merchant State'].fillna('0')\n",
    "df['Errors?']=df['Errors?'].fillna('unknown')\n",
    "df['Apartment']=df['Apartment'].fillna('0')\n",
    "df['Location_Income_toDebt']=df['Location_Income_toDebt'].fillna(df['Location_Income_toDebt'].mean())"
   ],
   "id": "bc8121ac26ad9876",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"Transcation_Time\"] = df[\"Year\"].astype(str) + '-' + df[\"Month\"].astype(str) + '-' + df[\"Day\"].astype(str) + ' ' + df[\"Time\"]\n",
    "df[\"Transcation_Time\"] = pd.to_datetime(df[\"Transcation_Time\"])\n",
    "\n",
    "## Day of the weel\n",
    "df[\"Weekday\"] = df[\"Transcation_Time\"].dt.day_name()\n",
    "\n",
    "## Split the time of day into 8 different periods based on hour\n",
    "df['Time_of_Day'] = ''\n",
    "df.loc[(df['Transcation_Time'].dt.hour >= 23) | (df['Transcation_Time'].dt.hour < 2), 'Time_of_Day'] = 'Midnight'\n",
    "df.loc[(df['Transcation_Time'].dt.hour >= 2) & (df['Transcation_Time'].dt.hour < 5), 'Time_of_Day'] = 'Early Morning'\n",
    "df.loc[(df['Transcation_Time'].dt.hour >= 5) & (df['Transcation_Time'].dt.hour < 8), 'Time_of_Day'] = 'Morning'\n",
    "df.loc[(df['Transcation_Time'].dt.hour >= 8) & (df['Transcation_Time'].dt.hour < 11), 'Time_of_Day'] = 'Late Morning'\n",
    "df.loc[(df['Transcation_Time'].dt.hour >= 11) & (df['Transcation_Time'].dt.hour < 14), 'Time_of_Day'] = 'Noon'\n",
    "df.loc[(df['Transcation_Time'].dt.hour >= 14) & (df['Transcation_Time'].dt.hour < 17), 'Time_of_Day'] = 'Afternoon'\n",
    "df.loc[(df['Transcation_Time'].dt.hour >= 17) & (df['Transcation_Time'].dt.hour < 20), 'Time_of_Day'] = 'Evening'\n",
    "df.loc[(df['Transcation_Time'].dt.hour >= 20) & (df['Transcation_Time'].dt.hour < 23), 'Time_of_Day'] = 'Late Night'\n"
   ],
   "id": "d4cace8893f07b6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['Per Capita Income - Zipcode'] = df['Per Capita Income - Zipcode'].str.replace(\"$\", \"\").astype(float)",
   "id": "b44d9ab27662e4da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_new = reduce_mem_usage(df.drop(columns=[\"Merchant Name\", \"Merchant State\", \"Zip\",'Time','Merchant City','Acct Open Date','Expires','Address','City','State']))",
   "id": "9a62570a9f3fcca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_new.to_csv('df_new', index=False)",
   "id": "415a92fac927a690",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T05:08:03.120475Z",
     "start_time": "2024-06-06T05:06:29.104383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_new = reduce_mem_usage(pd.read_csv('df_new'))\n",
    "df_new[\"Is Fraud?\"] = df_new[\"Is Fraud?\"].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "df_new['transaction_hour'] = pd.to_datetime(df_new['Transcation_Time']).dt.hour\n",
    "df_new = df_new.drop(columns=['Transcation_Time'])"
   ],
   "id": "eaa96a153d156799",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 4511.89 Mb (46.1% reduction)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T05:08:07.733342Z",
     "start_time": "2024-06-06T05:08:03.130486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = df_new.drop(columns=['Is Fraud?'])\n",
    "y = df_new['Is Fraud?']\n",
    "X = reduce_mem_usage(X)"
   ],
   "id": "63882097be3b8e47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 4163.03 Mb (1.6% reduction)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y.to_csv('y.csv', index=False)",
   "id": "68aa496c688c87a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T05:08:26.383564Z",
     "start_time": "2024-06-06T05:08:07.734346Z"
    }
   },
   "cell_type": "code",
   "source": "X.replace([np.inf, -np.inf], np.nan, inplace=True)",
   "id": "9e20e73f2579722c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T05:08:29.166706Z",
     "start_time": "2024-06-06T05:08:26.385579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X['Person_Location_Income_ratio']=X['Person_Location_Income_ratio'].fillna(0)\n",
    "X['Person_Income_toDebt']=X['Person_Income_toDebt'].fillna(0)\n",
    "X['Location_Income_toDebt']=X['Location_Income_toDebt'].fillna(0)\n",
    "X = X.drop(columns=['Person','Card Number'])"
   ],
   "id": "7e319626c8539c02",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T05:14:49.393766Z",
     "start_time": "2024-06-06T05:10:54.523116Z"
    }
   },
   "cell_type": "code",
   "source": "X.to_csv('X', index=False)",
   "id": "230c62369e7bbe58",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### data clean ",
   "id": "f8158b2738df94f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "numerical_columns_selector = selector(dtype_exclude=object)\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "numerical_columns = numerical_columns_selector(X)\n",
    "categorical_columns = categorical_columns_selector(X)\n",
    "for col in categorical_columns:\n",
    "    X[col] = X[col].astype(str)\n",
    "categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "numerical_preprocessor = StandardScaler()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"one-hot-encoder\", categorical_preprocessor, categorical_columns),\n",
    "        (\"standard_scaler\", numerical_preprocessor, numerical_columns)\n",
    "    ]\n",
    ")\n",
    "## Transform the variable\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "feature_names = preprocessor.get_feature_names_out()"
   ],
   "id": "2f8e9c228389eb1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T05:15:16.861530Z",
     "start_time": "2024-06-06T05:15:16.856083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "datatime = datetime.now()"
   ],
   "id": "a15423585b0677ae",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T05:15:26.001408Z",
     "start_time": "2024-06-06T05:15:23.177677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# 选择器帮助选择数据类型\n",
    "numerical_columns_selector = selector(dtype_exclude=object)\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "\n",
    "# 选择数值型和类别型列\n",
    "numerical_columns = numerical_columns_selector(X)\n",
    "categorical_columns = categorical_columns_selector(X)\n",
    "\n",
    "# 将类别型变量转换为字符串类型\n",
    "for col in categorical_columns:\n",
    "    X[col] = X[col].astype(str)\n",
    "\n",
    "# 类别型预处理器\n",
    "categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
    "\n",
    "# 数值型预处理器\n",
    "standard_scaler_columns = ['Amount', 'Credit Limit', 'Per Capita Income - Zipcode', 'Yearly Income - Person', 'Total Debt', 'FICO Score']\n",
    "min_max_scaler_columns = ['Latitude', 'Longitude']\n",
    "\n",
    "# 标准化处理\n",
    "standard_scaler = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # 处理缺失值\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# 正则化处理\n",
    "min_max_scaler = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # 处理缺失值\n",
    "    ('scaler', MinMaxScaler())\n",
    "])"
   ],
   "id": "b06076120cd3edb3",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T07:53:18.072035Z",
     "start_time": "2024-06-06T07:53:18.031832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 日期处理（如果需要）\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CustomDateTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        current_year = datetime.now().year\n",
    "        X = X.copy()\n",
    "        X['Card_Age'] = current_year - X['Open_Year']\n",
    "        X['Expires_In'] = X['Expire_Year'] - current_year\n",
    "        return X[['Card_Age', 'Expires_In']]\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return ['Card_Age', 'Expires_In']\n",
    "\n",
    "# 使用自定义转换器\n",
    "date_transformer = CustomDateTransformer()\n",
    "\n",
    "# ColumnTransformer配置\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"one-hot-encoder\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_columns),\n",
    "        (\"standard_scaler\", StandardScaler(), standard_scaler_columns),\n",
    "        (\"min_max_scaler\", MinMaxScaler(), min_max_scaler_columns),\n",
    "        (\"date_processor\", date_transformer, ['Open_Year', 'Expire_Year'])\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X = reduce_mem_usage(X)"
   ],
   "id": "7e9ab8f2856ee979",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'categorical_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[36], line 24\u001B[0m\n\u001B[0;32m     19\u001B[0m date_transformer \u001B[38;5;241m=\u001B[39m CustomDateTransformer()\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# ColumnTransformer配置\u001B[39;00m\n\u001B[0;32m     22\u001B[0m preprocessor \u001B[38;5;241m=\u001B[39m ColumnTransformer(\n\u001B[0;32m     23\u001B[0m     transformers\u001B[38;5;241m=\u001B[39m[\n\u001B[1;32m---> 24\u001B[0m         (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mone-hot-encoder\u001B[39m\u001B[38;5;124m\"\u001B[39m, OneHotEncoder(handle_unknown\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m), categorical_columns),\n\u001B[0;32m     25\u001B[0m         (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstandard_scaler\u001B[39m\u001B[38;5;124m\"\u001B[39m, StandardScaler(), standard_scaler_columns),\n\u001B[0;32m     26\u001B[0m         (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmin_max_scaler\u001B[39m\u001B[38;5;124m\"\u001B[39m, MinMaxScaler(), min_max_scaler_columns),\n\u001B[0;32m     27\u001B[0m         (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdate_processor\u001B[39m\u001B[38;5;124m\"\u001B[39m, date_transformer, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOpen_Year\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpire_Year\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     28\u001B[0m     ],\n\u001B[0;32m     29\u001B[0m     remainder\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     30\u001B[0m )\n\u001B[0;32m     32\u001B[0m X \u001B[38;5;241m=\u001B[39m reduce_mem_usage(X)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'categorical_columns' is not defined"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X.info()",
   "id": "416e4ac45acf4afa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T05:17:23.260690Z",
     "start_time": "2024-06-06T05:15:34.436565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 转换变量\n",
    "X_preprocessed_new = preprocessor.fit_transform(X)"
   ],
   "id": "ca76ae7d671d0cf1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T07:53:13.113649Z",
     "start_time": "2024-06-06T07:53:13.089863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 获取新的特征名称，用于模型训练后查看特征重要性等信息\n",
    "feature_names_new = preprocessor.get_feature_names_out()"
   ],
   "id": "1f4759cf6374efb6",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 获取新的特征名称，用于模型训练后查看特征重要性等信息\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m feature_names_new \u001B[38;5;241m=\u001B[39m preprocessor\u001B[38;5;241m.\u001B[39mget_feature_names_out()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'preprocessor' is not defined"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "类别型变量：使用 OneHotEncoder 转换。\n",
    "标准化数值型变量：选择了一些关键的财务指标和评分进行标凈化。\n",
    "正则化数值型变量：选择了地理位置坐标进行正则化处理，以保证它们的比例和范围是统一的。\n",
    "日期处理：如果需要处理日期信息，这里提供了一个函数转换器来计算日期相关的新特征，比如信用卡的有效期等。"
   ],
   "id": "59da0c929f558692"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T05:31:34.093009Z",
     "start_time": "2024-06-06T05:18:35.323520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pd.DataFrame(feature_names_new).to_csv('feature_names', index=False)\n",
    "pd.DataFrame(X_preprocessed_new).to_csv('X_preprocessed', index=False)"
   ],
   "id": "8255462d4a343765",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7382f0e07a2eabba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### get sample",
   "id": "db62a0c16ed1a8ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T01:06:06.533223Z",
     "start_time": "2024-06-07T01:06:06.528389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def resample_split(rsd, X):\n",
    "    # Calculate the desired number of fraud cases based on the desired proportion\n",
    "    desired_proportion = 0.05\n",
    "    total_samples = 50000\n",
    "    fraud_samples = int(total_samples * desired_proportion)\n",
    "    \n",
    "    # Create RandomUnderSampler with the desired sampling strategy\n",
    "    rus = RandomUnderSampler(sampling_strategy={0: total_samples - fraud_samples, 1: fraud_samples}, random_state = rsd)\n",
    "    \n",
    "    # Apply random undersampling to the original dataset\n",
    "    X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "    \n",
    "    # Split the resampled data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state = rsd)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, feature_names_new"
   ],
   "id": "efcc47feb63e51cd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T01:06:07.045365Z",
     "start_time": "2024-06-07T01:06:07.042547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## model evaluation\n",
    "def cus_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return accuracy, auc, precision, recall, f1"
   ],
   "id": "b687675175c44d43",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T01:06:08.240163Z",
     "start_time": "2024-06-07T01:06:08.234662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "sd = random_numbers = random.sample(range(1000, 10000), 5)\n",
    "sd"
   ],
   "id": "ec94bfcaebd0c0f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6171, 2292, 4399, 8125, 2492]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LightGBM",
   "id": "5fd2963ae6f6248e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "67ec27d1f62584b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:44:35.525864Z",
     "start_time": "2024-06-07T02:38:57.717038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_preprocessed_new = reduce_mem_usage(pd.read_csv('X_preprocessed'))\n",
    "y = reduce_mem_usage(pd.read_csv('y'))\n",
    "y = y.drop(columns=['Unnamed: 0'])\n",
    "feature_names_new  = reduce_mem_usage(pd.read_csv('feature_names'))"
   ],
   "id": "34dcc454092e26d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 4186.29 Mb (74.4% reduction)\n",
      "Mem. usage decreased to 116.29 Mb (68.7% reduction)\n",
      "Mem. usage decreased to  0.00 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:45:09.650561Z",
     "start_time": "2024-06-07T02:45:06.257140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_names_new_list = feature_names_new.iloc[:,0].tolist()\n",
    "X_preprocessed = X_preprocessed_new.copy()\n",
    "X_preprocessed.columns = feature_names_new_list"
   ],
   "id": "58bb5ae3a16bc30b",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:13:12.337365Z",
     "start_time": "2024-06-07T03:13:12.327547Z"
    }
   },
   "cell_type": "code",
   "source": "X_preprocessed_new.info()",
   "id": "a132af5e155240a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24386900 entries, 0 to 24386899\n",
      "Data columns (total 88 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   0       float16\n",
      " 1   1       float16\n",
      " 2   2       float16\n",
      " 3   3       float16\n",
      " 4   4       float16\n",
      " 5   5       float16\n",
      " 6   6       float16\n",
      " 7   7       float16\n",
      " 8   8       float16\n",
      " 9   9       float16\n",
      " 10  10      float16\n",
      " 11  11      float16\n",
      " 12  12      float16\n",
      " 13  13      float16\n",
      " 14  14      float16\n",
      " 15  15      float16\n",
      " 16  16      float16\n",
      " 17  17      float16\n",
      " 18  18      float16\n",
      " 19  19      float16\n",
      " 20  20      float16\n",
      " 21  21      float16\n",
      " 22  22      float16\n",
      " 23  23      float16\n",
      " 24  24      float16\n",
      " 25  25      float16\n",
      " 26  26      float16\n",
      " 27  27      float16\n",
      " 28  28      float16\n",
      " 29  29      float16\n",
      " 30  30      float16\n",
      " 31  31      float16\n",
      " 32  32      float16\n",
      " 33  33      float16\n",
      " 34  34      float16\n",
      " 35  35      float16\n",
      " 36  36      float16\n",
      " 37  37      float16\n",
      " 38  38      float16\n",
      " 39  39      float16\n",
      " 40  40      float16\n",
      " 41  41      float16\n",
      " 42  42      float16\n",
      " 43  43      float16\n",
      " 44  44      float16\n",
      " 45  45      float16\n",
      " 46  46      float16\n",
      " 47  47      float16\n",
      " 48  48      float16\n",
      " 49  49      float16\n",
      " 50  50      float16\n",
      " 51  51      float16\n",
      " 52  52      float16\n",
      " 53  53      float16\n",
      " 54  54      float16\n",
      " 55  55      float16\n",
      " 56  56      float16\n",
      " 57  57      float16\n",
      " 58  58      float16\n",
      " 59  59      float16\n",
      " 60  60      float16\n",
      " 61  61      float16\n",
      " 62  62      float16\n",
      " 63  63      float16\n",
      " 64  64      float16\n",
      " 65  65      float16\n",
      " 66  66      float16\n",
      " 67  67      float16\n",
      " 68  68      float16\n",
      " 69  69      float16\n",
      " 70  70      float16\n",
      " 71  71      float16\n",
      " 72  72      float16\n",
      " 73  73      float16\n",
      " 74  74      float16\n",
      " 75  75      float16\n",
      " 76  76      float16\n",
      " 77  77      float16\n",
      " 78  78      float16\n",
      " 79  79      float16\n",
      " 80  80      float16\n",
      " 81  81      float32\n",
      " 82  82      float16\n",
      " 83  83      float32\n",
      " 84  84      float16\n",
      " 85  85      float16\n",
      " 86  86      float16\n",
      " 87  87      float16\n",
      "dtypes: float16(86), float32(2)\n",
      "memory usage: 4.1 GB\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SHAP evaluation",
   "id": "c8968db4063fcfe7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:46:20.014824Z",
     "start_time": "2024-06-07T02:45:15.449046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import shap\n",
    "\n",
    "results_SHAP = {}\n",
    "important_features_overall = {}  # To track overall importance across all seeds\n",
    "\n",
    "for rsd in sd:\n",
    "    ## Perform Undersampling to make the data more balance\n",
    "    X_train, X_test, y_train, y_test, feature_names = resample_split(rsd,X_preprocessed_new)\n",
    "    \n",
    "    ## Create LightGBM dataset\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_test, y_test, reference = lgb_train)\n",
    "    \n",
    "    ## Define the parameters\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': {'binary_logloss', 'binary_error', 'auc'},\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.1,\n",
    "        'lambda_l1': 0.01, ## Avoid overfitting\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    \n",
    "    model = lgb.train(params, lgb_train, num_boost_round=300, valid_sets=[lgb_train, lgb_eval])\n",
    "    \n",
    "    # SHAP 值分析\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    \n",
    "    # 得到平均绝对 SHAP 值，表示整体特征重要性\n",
    "    shap_sum = np.abs(shap_values).mean(axis=0)\n",
    "    shap_sum = pd.DataFrame(shap_sum)\n",
    "\n",
    "    # 确保 feature_names 是一个列表或类似数组的结构，且长度与 shap_sum 一致\n",
    "    # 创建 DataFrame\n",
    "    importance_df = pd.concat([feature_names_new, shap_sum], axis=1)\n",
    "    importance_df.columns = ['feature', 'shap_importance']\n",
    "\n",
    "    # 按重要性排序\n",
    "    importance_df.sort_values(by='shap_importance', ascending=False, inplace=True)\n",
    "\n",
    "    #importance_df = pd.DataFrame([feature_names, shap_sum.tolist()]).T\n",
    "    #importance_df.columns = ['feature', 'shap_importance']\n",
    "    #importance_df = importance_df.sort_values('shap_importance', ascending=False)\n",
    "    \n",
    "    # 保存每次结果\n",
    "    top_features = importance_df.head(20)['feature'].tolist()  # 取重要性最高的20个特征\n",
    "    important_features_overall[rsd] = top_features  # Tracking feature importance\n",
    "    \n",
    "    # Predict the model using the testing sets\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy, auc, precision, recall, f1 = cus_metrics(y_test, y_pred)\n",
    "    \n",
    "    # 保存结果\n",
    "    results_SHAP[f\"Seed {rsd}\"] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Top 20 Important Features by SHAP': top_features\n",
    "    }\n",
    "    print('Round finished for seed:', rsd)\n",
    "\n",
    "# 分析哪些特征在多个随机种子中重复出现\n",
    "final_selected_features = pd.Series([feat for sublist in important_features_overall.values() for feat in sublist])\n",
    "final_selected_features_SHAP = final_selected_features.value_counts().index.tolist()[:20]  # 选择出现次数最多的前20个特征\n",
    "\n",
    "# 输出最终选定的特征\n",
    "print(\"Final selected features based on SHAP importance across all seeds:\", final_selected_features)\n"
   ],
   "id": "70eec181048345a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round finished for seed: 6171\n",
      "Round finished for seed: 2292\n",
      "Round finished for seed: 4399\n",
      "Round finished for seed: 8125\n",
      "Round finished for seed: 2492\n",
      "Final selected features based on SHAP importance across all seeds: 0                                   remainder__MCC\n",
      "1     one-hot-encoder__Use Chip_Online Transaction\n",
      "2                                  remainder__Year\n",
      "3                      remainder__transaction_hour\n",
      "4                          standard_scaler__Amount\n",
      "                          ...                     \n",
      "95                          remainder__Current Age\n",
      "96    standard_scaler__Per Capita Income - Zipcode\n",
      "97                remainder__Year PIN last Changed\n",
      "98         remainder__Person_Location_Income_ratio\n",
      "99                        min_max_scaler__Latitude\n",
      "Length: 100, dtype: object\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:51:39.718709Z",
     "start_time": "2024-06-07T02:51:39.164232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#X_preprocessed_new_df = pd.DataFrame(X_preprocessed_new, columns=feature_names_new_list)\n",
    "\n",
    "X_selected_SHAP = X_preprocessed[final_selected_features_SHAP]\n",
    "\n",
    "# 检查所选特征的数据集\n",
    "print(X_selected_SHAP.head())\n",
    "\n",
    "# 可选：保存新的特征数据集\n",
    "#X_selected.to_csv('X_selected.csv', index=False)\n",
    "#print(\"Selected features dataset saved as X_selected.csv.\")\n"
   ],
   "id": "16f256761121f96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   remainder__MCC  standard_scaler__Credit Limit  remainder__Birth Year  \\\n",
      "0          5300.0                       0.742676                 1966.0   \n",
      "1          5412.0                       0.742676                 1966.0   \n",
      "2          5412.0                       0.742676                 1966.0   \n",
      "3          5652.0                       0.742676                 1966.0   \n",
      "4          5912.0                       0.742676                 1966.0   \n",
      "\n",
      "   one-hot-encoder__Use Chip_Online Transaction  \\\n",
      "0                                           0.0   \n",
      "1                                           0.0   \n",
      "2                                           0.0   \n",
      "3                                           0.0   \n",
      "4                                           0.0   \n",
      "\n",
      "   standard_scaler__Per Capita Income - Zipcode  standard_scaler__FICO Score  \\\n",
      "0                                      0.448242                     1.113281   \n",
      "1                                      0.448242                     1.113281   \n",
      "2                                      0.448242                     1.113281   \n",
      "3                                      0.448242                     1.113281   \n",
      "4                                      0.448242                     1.113281   \n",
      "\n",
      "   remainder__Day  remainder__CVV  remainder__Num Credit Cards  \\\n",
      "0             1.0           623.0                          5.0   \n",
      "1             1.0           623.0                          5.0   \n",
      "2             2.0           623.0                          5.0   \n",
      "3             2.0           623.0                          5.0   \n",
      "4             3.0           623.0                          5.0   \n",
      "\n",
      "   one-hot-encoder__Use Chip_Swipe Transaction  standard_scaler__Amount  \\\n",
      "0                                          1.0                 1.103516   \n",
      "1                                          1.0                -0.062988   \n",
      "2                                          1.0                 0.935059   \n",
      "3                                          1.0                 1.041016   \n",
      "4                                          1.0                 0.744141   \n",
      "\n",
      "   remainder__transaction_hour  remainder__Year  min_max_scaler__Latitude  \\\n",
      "0                          6.0           2002.0                   0.32959   \n",
      "1                          6.0           2002.0                   0.32959   \n",
      "2                          6.0           2002.0                   0.32959   \n",
      "3                         17.0           2002.0                   0.32959   \n",
      "4                          6.0           2002.0                   0.32959   \n",
      "\n",
      "   remainder__Month  remainder__Zipcode  min_max_scaler__Longitude  \\\n",
      "0               9.0             91750.0                   0.458984   \n",
      "1               9.0             91750.0                   0.458984   \n",
      "2               9.0             91750.0                   0.458984   \n",
      "3               9.0             91750.0                   0.458984   \n",
      "4               9.0             91750.0                   0.458984   \n",
      "\n",
      "   remainder__Current Age  remainder__Year PIN last Changed  \\\n",
      "0                    53.0                            2008.0   \n",
      "1                    53.0                            2008.0   \n",
      "2                    53.0                            2008.0   \n",
      "3                    53.0                            2008.0   \n",
      "4                    53.0                            2008.0   \n",
      "\n",
      "   remainder__Person_Income_toDebt  \n",
      "0                         0.467773  \n",
      "1                         0.467773  \n",
      "2                         0.467773  \n",
      "3                         0.467773  \n",
      "4                         0.467773  \n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:52:00.363598Z",
     "start_time": "2024-06-07T02:51:42.749500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result_new_SHAP = {}\n",
    "for rsd in sd:\n",
    "    ## Perform Undersampling to make the data more balance\n",
    "    X_train, X_test, y_train, y_test, feature_names = resample_split(rsd, X_selected_SHAP)\n",
    "    \n",
    "    ## Create LightGBM dataset\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_test, y_test, reference = lgb_train)\n",
    "    \n",
    "    ## Define the parameters\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': {'binary_logloss', 'binary_error', 'auc'},\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.1,\n",
    "        'lambda_l1': 0.01, ## Avoid overfitting\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    \n",
    "    ## Train the model\n",
    "    model = lgb.train(params, lgb_train, num_boost_round = 300, valid_sets = lgb_train)\n",
    "    \n",
    "    ## Predict the model using the testing sets\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "    \n",
    "    ## obtain the model performance metrics\n",
    "    accuracy, auc, precision, recall, f1 = cus_metrics(y_test, y_pred)  \n",
    "    ## save the result\n",
    "    result_new_SHAP[f\"Seed {rsd}\"] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "    }\n",
    "    print('Round finished for seed:', rsd)"
   ],
   "id": "9b89bbaf74d1c9e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Round finished for seed: 6171\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Round finished for seed: 2292\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Round finished for seed: 4399\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Round finished for seed: 8125\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Round finished for seed: 2492\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### build-in evaluation",
   "id": "a0d3457766da3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:52:37.223325Z",
     "start_time": "2024-06-07T02:52:12.328100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "results_b = {}\n",
    "important_features_overall = {}  # To track overall importance across all seeds\n",
    "\n",
    "for rsd in sd:\n",
    "    ## Perform Undersampling to balance the data\n",
    "    X_train, X_test, y_train, y_test, feature_names = resample_split(rsd, X_preprocessed_new)\n",
    "    \n",
    "    ## Create LightGBM dataset\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "    \n",
    "    ## Define the parameters\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': {'binary_logloss', 'binary_error', 'auc'},\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.1,\n",
    "        'lambda_l1': 0.01,  # To avoid overfitting\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    \n",
    "    ## Train the model\n",
    "    model = lgb.train(params, lgb_train, num_boost_round=300, valid_sets=[lgb_train, lgb_eval])\n",
    "    \n",
    "    ## Get feature importance\n",
    "    feature_importance = model.feature_importance(importance_type='gain')\n",
    "    feature_names_list = feature_names.iloc[:,0].tolist()\n",
    "    importance_df = pd.DataFrame({'feature': feature_names_list, 'importance': feature_importance})\n",
    "    importance_df.sort_values(by='importance', ascending=False, inplace=True)\n",
    "    \n",
    "    ## Save the results for this round\n",
    "    top_features = importance_df.head(20)['feature'].tolist()  # Get the top 20 important features\n",
    "    important_features_overall[rsd] = top_features  # Tracking feature importance\n",
    "    \n",
    "    ## Predict using the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "    \n",
    "    ## Calculate metrics\n",
    "    accuracy, auc, precision, recall, f1 = cus_metrics(y_test, y_pred)\n",
    "    \n",
    "    ## Store results\n",
    "    results_b[f\"Seed {rsd}\"] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Top 20 Important Features by Gain': top_features\n",
    "    }\n",
    "    print('Round finished for seed:', rsd)\n",
    "\n",
    "## Identify the most frequently important features across all seeds\n",
    "final_selected_features = pd.Series([feat for sublist in important_features_overall.values() for feat in sublist])\n",
    "final_selected_features_b = final_selected_features.value_counts().index.tolist()[:20]  # Select the top 20 most frequently important features\n",
    "\n",
    "## Output the final selected features\n",
    "print(\"Final selected features based on gain importance across all seeds:\", final_selected_features)\n"
   ],
   "id": "baf601e27f11e8cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round finished for seed: 6171\n",
      "Round finished for seed: 2292\n",
      "Round finished for seed: 4399\n",
      "Round finished for seed: 8125\n",
      "Round finished for seed: 2492\n",
      "Final selected features based on gain importance across all seeds: 0                                   remainder__MCC\n",
      "1     one-hot-encoder__Use Chip_Online Transaction\n",
      "2                          standard_scaler__Amount\n",
      "3                                  remainder__Year\n",
      "4                      remainder__transaction_hour\n",
      "                          ...                     \n",
      "95                        date_processor__Card_Age\n",
      "96                     standard_scaler__Total Debt\n",
      "97                 remainder__Person_Income_toDebt\n",
      "98                     remainder__Num Credit Cards\n",
      "99                       remainder__Retirement Age\n",
      "Length: 100, dtype: object\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:52:42.802157Z",
     "start_time": "2024-06-07T02:52:42.077494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_selected_b = X_preprocessed[final_selected_features_b]\n",
    "\n",
    "# 检查所选特征的数据集\n",
    "print(X_selected_b.head())\n",
    "\n",
    "# 可选：保存新的特征数据集\n",
    "#X_selected.to_csv('X_selected.csv', index=False)\n",
    "#print(\"Selected features dataset saved as X_selected.csv.\")"
   ],
   "id": "cfbc3c46f787228e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   remainder__MCC  standard_scaler__Per Capita Income - Zipcode  \\\n",
      "0          5300.0                                      0.448242   \n",
      "1          5412.0                                      0.448242   \n",
      "2          5412.0                                      0.448242   \n",
      "3          5652.0                                      0.448242   \n",
      "4          5912.0                                      0.448242   \n",
      "\n",
      "   remainder__Zipcode  remainder__Month  standard_scaler__Total Debt  \\\n",
      "0             91750.0               9.0                      1.31543   \n",
      "1             91750.0               9.0                      1.31543   \n",
      "2             91750.0               9.0                      1.31543   \n",
      "3             91750.0               9.0                      1.31543   \n",
      "4             91750.0               9.0                      1.31543   \n",
      "\n",
      "   one-hot-encoder__Use Chip_Online Transaction  remainder__Day  \\\n",
      "0                                           0.0             1.0   \n",
      "1                                           0.0             1.0   \n",
      "2                                           0.0             2.0   \n",
      "3                                           0.0             2.0   \n",
      "4                                           0.0             3.0   \n",
      "\n",
      "   min_max_scaler__Longitude  standard_scaler__Yearly Income - Person  \\\n",
      "0                   0.458984                                 0.535156   \n",
      "1                   0.458984                                 0.535156   \n",
      "2                   0.458984                                 0.535156   \n",
      "3                   0.458984                                 0.535156   \n",
      "4                   0.458984                                 0.535156   \n",
      "\n",
      "   min_max_scaler__Latitude  remainder__CVV  standard_scaler__FICO Score  \\\n",
      "0                   0.32959           623.0                     1.113281   \n",
      "1                   0.32959           623.0                     1.113281   \n",
      "2                   0.32959           623.0                     1.113281   \n",
      "3                   0.32959           623.0                     1.113281   \n",
      "4                   0.32959           623.0                     1.113281   \n",
      "\n",
      "   standard_scaler__Credit Limit  remainder__transaction_hour  \\\n",
      "0                       0.742676                          6.0   \n",
      "1                       0.742676                          6.0   \n",
      "2                       0.742676                          6.0   \n",
      "3                       0.742676                         17.0   \n",
      "4                       0.742676                          6.0   \n",
      "\n",
      "   remainder__Year  standard_scaler__Amount  remainder__Num Credit Cards  \\\n",
      "0           2002.0                 1.103516                          5.0   \n",
      "1           2002.0                -0.062988                          5.0   \n",
      "2           2002.0                 0.935059                          5.0   \n",
      "3           2002.0                 1.041016                          5.0   \n",
      "4           2002.0                 0.744141                          5.0   \n",
      "\n",
      "   remainder__Person_Income_toDebt  date_processor__Card_Age  \\\n",
      "0                         0.467773                      22.0   \n",
      "1                         0.467773                      22.0   \n",
      "2                         0.467773                      22.0   \n",
      "3                         0.467773                      22.0   \n",
      "4                         0.467773                      22.0   \n",
      "\n",
      "   remainder__Retirement Age  \n",
      "0                       66.0  \n",
      "1                       66.0  \n",
      "2                       66.0  \n",
      "3                       66.0  \n",
      "4                       66.0  \n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:53:04.073288Z",
     "start_time": "2024-06-07T02:52:45.664476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result_new_b = {}\n",
    "for rsd in sd:\n",
    "    ## Perform Undersampling to make the data more balance\n",
    "    X_train, X_test, y_train, y_test, feature_names = resample_split(rsd, X_selected_b)\n",
    "    \n",
    "    ## Create LightGBM dataset\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_test, y_test, reference = lgb_train)\n",
    "    \n",
    "    ## Define the parameters\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': {'binary_logloss', 'binary_error', 'auc'},\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.1,\n",
    "        'lambda_l1': 0.01, ## Avoid overfitting\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    \n",
    "    ## Train the model\n",
    "    model = lgb.train(params, lgb_train, num_boost_round = 300, valid_sets = lgb_train)\n",
    "    \n",
    "    ## Predict the model using the testing sets\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "    \n",
    "    ## obtain the model performance metrics\n",
    "    accuracy, auc, precision, recall, f1 = cus_metrics(y_test, y_pred)  \n",
    "    ## save the result\n",
    "    result_new_b[f\"Seed {rsd}\"] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "    }\n",
    "    print('Round finished for seed:', rsd)"
   ],
   "id": "3c64aa93987c8b45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Round finished for seed: 6171\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Round finished for seed: 2292\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Round finished for seed: 4399\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Round finished for seed: 8125\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Round finished for seed: 2492\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Permutation importance evaluation ",
   "id": "977691cb5d82532c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:54:39.756314Z",
     "start_time": "2024-06-07T02:53:08.621738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "results_p = {}\n",
    "important_features_overall = {}  # To track overall importance across all seeds\n",
    "\n",
    "for rsd in sd:\n",
    "    ## Perform Undersampling to balance the data\n",
    "    X_train, X_test, y_train, y_test, feature_names = resample_split(rsd, X_preprocessed_new)\n",
    "    \n",
    "    ## Define the model\n",
    "    model = lgb.LGBMClassifier(\n",
    "        boosting_type='gbdt',\n",
    "        objective='binary',\n",
    "        num_leaves=31,\n",
    "        learning_rate=0.1,\n",
    "        lambda_l1=0.01,  # To avoid overfitting\n",
    "        feature_fraction=0.9,\n",
    "        bagging_fraction=0.8,\n",
    "        bagging_freq=5,\n",
    "        verbose=0,\n",
    "        n_estimators=300,\n",
    "        random_state=rsd,\n",
    "    )\n",
    "    \n",
    "    ## Train the model\n",
    "    model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], eval_metric='auc')\n",
    "    \n",
    "    ## Compute Permutation Importance\n",
    "    perm_importance = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=rsd, n_jobs=-1)\n",
    "    \n",
    "    ## Organize results into DataFrame\n",
    "    feature_names_list = feature_names.iloc[:,0].tolist()\n",
    "    importance_df = pd.DataFrame({'feature': feature_names_list, 'importance': perm_importance.importances_mean})\n",
    "    importance_df.sort_values(by='importance', ascending=False, inplace=True)\n",
    "    \n",
    "    ## Save the results for this round\n",
    "    top_features = importance_df.head(20)['feature'].tolist()  # Get the top 20 important features\n",
    "    important_features_overall[rsd] = top_features  # Tracking feature importance\n",
    "    \n",
    "    ## Predict using the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    ## Calculate metrics\n",
    "    accuracy, auc, precision, recall, f1 = cus_metrics(y_test, y_pred)\n",
    "    \n",
    "    ## Store results\n",
    "    results_p[f\"Seed {rsd}\"] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Top 20 Important Features by Permutation Importance': top_features\n",
    "    }\n",
    "    print('Round finished for seed:', rsd)\n",
    "\n",
    "## Identify the most frequently important features across all seeds\n",
    "final_selected_features = pd.Series([feat for sublist in important_features_overall.values() for feat in sublist])\n",
    "final_selected_features_p = final_selected_features.value_counts().index.tolist()[:20]  # Select the top 20 most frequently important features\n",
    "\n",
    "## Output the final selected features\n",
    "print(\"Final selected features based on permutation importance across all seeds:\", final_selected_features)\n"
   ],
   "id": "4456d5461dc557c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Round finished for seed: 6171\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Round finished for seed: 2292\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Round finished for seed: 4399\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Round finished for seed: 8125\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Round finished for seed: 2492\n",
      "Final selected features based on permutation importance across all seeds: 0     one-hot-encoder__Use Chip_Online Transaction\n",
      "1                                   remainder__MCC\n",
      "2                          standard_scaler__Amount\n",
      "3                                  remainder__Year\n",
      "4                      remainder__transaction_hour\n",
      "                          ...                     \n",
      "95                 one-hot-encoder__Weekday_Sunday\n",
      "96                         remainder__Expire_Month\n",
      "97                       remainder__Retirement Age\n",
      "98                              remainder__Zipcode\n",
      "99                           remainder__Birth Year\n",
      "Length: 100, dtype: object\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. **\"permutation_importance 函数需要一个实现了 fit 方法的估计器对象\"**\n",
    "`permutation_importance` 是 `scikit-learn` 库中的一个函数，用来评估模型中各个特征的重要性。这个函数通过改变每个特征的值顺序（即排列）并计算这种改变对模型预测性能的影响来工作。为了能够进行这种评估，`permutation_importance` 需要能够自主地对数据进行预测，因此它要求传入的参数（即模型）必须有一个 `fit` 方法。`fit` 方法用于训练模型，即根据提供的数据调整模型的内部参数以最好地预测目标变量。\n",
    "\n",
    "### 2. **\"而 LightGBM 的 lgb.train 方法返回的是一个 Booster 对象，这个对象并没有 fit 方法\"**\n",
    "LightGBM 是一个高性能的梯度提升框架，它支持多种类型的接口。`lgb.train` 是 LightGBM 的底层接口，主要用于更精细的模型训练控制。使用 `lgb.train` 训练出来的模型是一个 `Booster` 对象，这是 LightGBM 的一个核心组件，用于持有和管理梯度提升模型的数据。虽然 `Booster` 对象可以用于预测，但它是专为 LightGBM 设计的，没有实现 `fit` 方法。`fit` 方法是 `scikit-learn` 风格的模型通常具备的，用于训练模型。\n",
    "\n",
    "由于 `permutation_importance` 需要一个具有 `fit` 方法的模型对象来进行特征重要性的评估，因此不能直接使用由 `lgb.train` 返回的 `Booster` 对象。相反，我们需要使用 LightGBM 的 `LGBMClassifier` 或 `LGBMRegressor`，这些都是与 `scikit-learn` 兼容的高层接口，支持 `fit` 方法，并可以无缝与 `scikit-learn` 的工具如 `permutation_importance` 配合使用。这样，你就可以直接在 LightGBM 模型上使用 `scikit-learn` 的各种功能，包括模型评估和特征选择等。"
   ],
   "id": "c8e95479b3a4c242"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "LightGBM\n",
    "LightGBM 是一个高性能的梯度提升框架，由 Microsoft 开发，用于构建和训练梯度提升树模型。这个框架主要面向两类用户：那些需要高效、快速训练大规模数据的研究人员和工程师，以及需要精细控制模型训练过程的高级用户。它支持各种自定义的优化和配置，包括但不限于并行训练、GPU 加速、处理大规模数据集等。\n",
    "\n",
    "lgb.LGBMClassifier\n",
    "lgb.LGBMClassifier 是 LightGBM 提供的一个高层次 API，它是一个分类器，封装了 LightGBM 的功能，使之符合 scikit-learn 的接口。这种封装的主要好处是能够让 LightGBM 的模型与 scikit-learn 的其他功能（如交叉验证、网格搜索以及其他各种模型评估和特征选择方法）无缝集成。简而言之，LGBMClassifier 提供了一种简便的方式来使用 LightGBM，同时保持与 scikit-learn 生态系统的兼容性。\n",
    "\n",
    "主要区别和使用场景\n",
    "兼容性：LGBMClassifier 与 scikit-learn 完全兼容，支持所有依赖于 scikit-learn 接口的方法和特性（例如使用 .fit()、.predict() 方法），而 lgb.train 返回的 Booster 对象则专门用于 LightGBM 内部使用，不直接支持 scikit-learn 的模式。\n",
    "易用性：LGBMClassifier 使得用户可以更方便地利用 scikit-learn 的诸多工具，如参数搜索、模型评估等，而不需要深入了解 LightGBM 的内部细节。\n",
    "功能性：使用 lgb.train 可能会更加复杂，但它提供了更高的灵活性和控制能力，适合需要对模型训练过程进行精细控制的场景。"
   ],
   "id": "cf8328e0aa38222"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:55:17.787307Z",
     "start_time": "2024-06-07T02:55:17.257394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "X_selected_p = X_preprocessed[final_selected_features_p]\n",
    "\n",
    "# 检查所选特征的数据集\n",
    "print(X_selected_p.head())\n",
    "\n",
    "# 可选：保存新的特征数据集\n",
    "#X_selected.to_csv('X_selected.csv', index=False)\n",
    "#print(\"Selected features dataset saved as X_selected.csv.\")"
   ],
   "id": "2adce88aaeb020b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   one-hot-encoder__Use Chip_Online Transaction  standard_scaler__Amount  \\\n",
      "0                                           0.0                 1.103516   \n",
      "1                                           0.0                -0.062988   \n",
      "2                                           0.0                 0.935059   \n",
      "3                                           0.0                 1.041016   \n",
      "4                                           0.0                 0.744141   \n",
      "\n",
      "   remainder__Year  remainder__transaction_hour  \\\n",
      "0           2002.0                          6.0   \n",
      "1           2002.0                          6.0   \n",
      "2           2002.0                          6.0   \n",
      "3           2002.0                         17.0   \n",
      "4           2002.0                          6.0   \n",
      "\n",
      "   one-hot-encoder__Use Chip_Swipe Transaction  remainder__MCC  \\\n",
      "0                                          1.0          5300.0   \n",
      "1                                          1.0          5412.0   \n",
      "2                                          1.0          5412.0   \n",
      "3                                          1.0          5652.0   \n",
      "4                                          1.0          5912.0   \n",
      "\n",
      "   remainder__Month  standard_scaler__Credit Limit  \\\n",
      "0               9.0                       0.742676   \n",
      "1               9.0                       0.742676   \n",
      "2               9.0                       0.742676   \n",
      "3               9.0                       0.742676   \n",
      "4               9.0                       0.742676   \n",
      "\n",
      "   one-hot-encoder__Weekday_Wednesday  \\\n",
      "0                                 0.0   \n",
      "1                                 0.0   \n",
      "2                                 0.0   \n",
      "3                                 0.0   \n",
      "4                                 0.0   \n",
      "\n",
      "   standard_scaler__Per Capita Income - Zipcode  \\\n",
      "0                                      0.448242   \n",
      "1                                      0.448242   \n",
      "2                                      0.448242   \n",
      "3                                      0.448242   \n",
      "4                                      0.448242   \n",
      "\n",
      "   one-hot-encoder__Use Chip_Chip Transaction  remainder__Retirement Age  \\\n",
      "0                                         0.0                       66.0   \n",
      "1                                         0.0                       66.0   \n",
      "2                                         0.0                       66.0   \n",
      "3                                         0.0                       66.0   \n",
      "4                                         0.0                       66.0   \n",
      "\n",
      "   one-hot-encoder__Weekday_Sunday  remainder__Num Credit Cards  \\\n",
      "0                              1.0                          5.0   \n",
      "1                              1.0                          5.0   \n",
      "2                              0.0                          5.0   \n",
      "3                              0.0                          5.0   \n",
      "4                              0.0                          5.0   \n",
      "\n",
      "   date_processor__Expires_In  one-hot-encoder__Card Type_Debit (Prepaid)  \\\n",
      "0                        -2.0                                         0.0   \n",
      "1                        -2.0                                         0.0   \n",
      "2                        -2.0                                         0.0   \n",
      "3                        -2.0                                         0.0   \n",
      "4                        -2.0                                         0.0   \n",
      "\n",
      "   remainder__Zipcode  remainder__CARD INDEX  remainder__Day  \\\n",
      "0             91750.0                    0.0             1.0   \n",
      "1             91750.0                    0.0             1.0   \n",
      "2             91750.0                    0.0             2.0   \n",
      "3             91750.0                    0.0             2.0   \n",
      "4             91750.0                    0.0             3.0   \n",
      "\n",
      "   remainder__Birth Year  \n",
      "0                 1966.0  \n",
      "1                 1966.0  \n",
      "2                 1966.0  \n",
      "3                 1966.0  \n",
      "4                 1966.0  \n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:55:36.831536Z",
     "start_time": "2024-06-07T02:55:17.788369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result_new_p = {}\n",
    "for rsd in sd:\n",
    "    ## Perform Undersampling to make the data more balance\n",
    "    X_train, X_test, y_train, y_test, feature_names = resample_split(rsd, X_selected_p)\n",
    "    \n",
    "    ## Create LightGBM dataset\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_test, y_test, reference = lgb_train)\n",
    "    \n",
    "    ## Define the parameters\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': {'binary_logloss', 'binary_error', 'auc'},\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.1,\n",
    "        'lambda_l1': 0.01, ## Avoid overfitting\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    \n",
    "    ## Train the model\n",
    "    model = lgb.train(params, lgb_train, num_boost_round = 300, valid_sets = lgb_train)\n",
    "    \n",
    "    ## Predict the model using the testing sets\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "    \n",
    "    ## obtain the model performance metrics\n",
    "    accuracy, auc, precision, recall, f1 = cus_metrics(y_test, y_pred)  \n",
    "    ## save the result\n",
    "    result_new_p[f\"Seed {rsd}\"] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "    }\n",
    "    print('Round finished for seed:', rsd)"
   ],
   "id": "3dfc5e6707dc6b7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Round finished for seed: 6171\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Round finished for seed: 2292\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Round finished for seed: 4399\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Round finished for seed: 8125\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "Round finished for seed: 2492\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SHAP result compare",
   "id": "bc560486bfcd7e94"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "405240d8901f1065",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:55:46.510672Z",
     "start_time": "2024-06-07T02:55:46.499870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "flattened_results = []\n",
    "for seed, data in results_SHAP.items():\n",
    "    row = {\n",
    "        'Seed': seed,\n",
    "        'Accuracy': data['Accuracy'],\n",
    "        'AUC': data['AUC'],\n",
    "        'Precision': data['Precision'],\n",
    "        'Recall': data['Recall'],\n",
    "        'F1 Score': data['F1 Score']\n",
    "    }\n",
    "    flattened_results.append(row)\n",
    "\n",
    "## Create a DataFrame from the flattened dictionary\n",
    "lightGBM_SHAP = pd.DataFrame(flattened_results)"
   ],
   "id": "1a329efe89b48f68",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:55:49.624647Z",
     "start_time": "2024-06-07T02:55:49.620458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "flattened_results = []\n",
    "for seed, data in result_new_SHAP.items():\n",
    "    row = {\n",
    "        'Seed': seed,\n",
    "        'Accuracy': data['Accuracy'],\n",
    "        'AUC': data['AUC'],\n",
    "        'Precision': data['Precision'],\n",
    "        'Recall': data['Recall'],\n",
    "        'F1 Score': data['F1 Score']\n",
    "    }\n",
    "    flattened_results.append(row)\n",
    "\n",
    "## Create a DataFrame from the flattened dictionary\n",
    "lightGBM_new_SHAP = pd.DataFrame(flattened_results)"
   ],
   "id": "2bee171e6168fe19",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:55:49.645784Z",
     "start_time": "2024-06-07T02:55:49.625696Z"
    }
   },
   "cell_type": "code",
   "source": "lightGBM_SHAP",
   "id": "7ab573ebfd8bf3d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Seed  Accuracy       AUC  Precision  Recall  F1 Score\n",
       "0  Seed 6171    0.9772  0.799474   0.912121   0.602  0.725301\n",
       "1  Seed 2292    0.9766  0.799158   0.895833   0.602  0.720096\n",
       "2  Seed 4399    0.9758  0.797789   0.877193   0.600  0.712589\n",
       "3  Seed 8125    0.9762  0.797053   0.889881   0.598  0.715311\n",
       "4  Seed 2492    0.9756  0.797684   0.872093   0.600  0.710900"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seed 6171</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>0.799474</td>\n",
       "      <td>0.912121</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.725301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seed 2292</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.799158</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.720096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seed 4399</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.797789</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.712589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seed 8125</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>0.797053</td>\n",
       "      <td>0.889881</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.715311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seed 2492</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.797684</td>\n",
       "      <td>0.872093</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.710900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:55:49.652661Z",
     "start_time": "2024-06-07T02:55:49.646793Z"
    }
   },
   "cell_type": "code",
   "source": "lightGBM_new_SHAP",
   "id": "b07274f093eaadbf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Seed  Accuracy       AUC  Precision  Recall  F1 Score\n",
       "0  Seed 6171    0.9777  0.807316   0.906158   0.618  0.734839\n",
       "1  Seed 2292    0.9769  0.808789   0.881020   0.622  0.729191\n",
       "2  Seed 4399    0.9760  0.798842   0.880117   0.602  0.714964\n",
       "3  Seed 8125    0.9761  0.794158   0.894260   0.592  0.712395\n",
       "4  Seed 2492    0.9755  0.791000   0.885196   0.586  0.705174"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seed 6171</td>\n",
       "      <td>0.9777</td>\n",
       "      <td>0.807316</td>\n",
       "      <td>0.906158</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.734839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seed 2292</td>\n",
       "      <td>0.9769</td>\n",
       "      <td>0.808789</td>\n",
       "      <td>0.881020</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.729191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seed 4399</td>\n",
       "      <td>0.9760</td>\n",
       "      <td>0.798842</td>\n",
       "      <td>0.880117</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.714964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seed 8125</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.794158</td>\n",
       "      <td>0.894260</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.712395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seed 2492</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.791000</td>\n",
       "      <td>0.885196</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.705174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Build_in rusult compare",
   "id": "f3bbcd82e0a49e6b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:55:52.796244Z",
     "start_time": "2024-06-07T02:55:52.791330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "flattened_results = []\n",
    "for seed, data in results_b.items():\n",
    "    row = {\n",
    "        'Seed': seed,\n",
    "        'Accuracy': data['Accuracy'],\n",
    "        'AUC': data['AUC'],\n",
    "        'Precision': data['Precision'],\n",
    "        'Recall': data['Recall'],\n",
    "        'F1 Score': data['F1 Score']\n",
    "    }\n",
    "    flattened_results.append(row)\n",
    "\n",
    "## Create a DataFrame from the flattened dictionary\n",
    "lightGBM_b = pd.DataFrame(flattened_results)"
   ],
   "id": "be62d47db7433148",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:55:52.802128Z",
     "start_time": "2024-06-07T02:55:52.797254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "flattened_results = []\n",
    "for seed, data in result_new_b.items():\n",
    "    row = {\n",
    "        'Seed': seed,\n",
    "        'Accuracy': data['Accuracy'],\n",
    "        'AUC': data['AUC'],\n",
    "        'Precision': data['Precision'],\n",
    "        'Recall': data['Recall'],\n",
    "        'F1 Score': data['F1 Score']\n",
    "    }\n",
    "    flattened_results.append(row)\n",
    "\n",
    "## Create a DataFrame from the flattened dictionary\n",
    "lightGBM_new_b = pd.DataFrame(flattened_results)"
   ],
   "id": "57d6a5f70a682946",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:55:52.810139Z",
     "start_time": "2024-06-07T02:55:52.803144Z"
    }
   },
   "cell_type": "code",
   "source": "lightGBM_b",
   "id": "d827db35cd3515c8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Seed  Accuracy       AUC  Precision  Recall  F1 Score\n",
       "0  Seed 6171    0.9772  0.799474   0.912121   0.602  0.725301\n",
       "1  Seed 2292    0.9766  0.799158   0.895833   0.602  0.720096\n",
       "2  Seed 4399    0.9758  0.797789   0.877193   0.600  0.712589\n",
       "3  Seed 8125    0.9762  0.797053   0.889881   0.598  0.715311\n",
       "4  Seed 2492    0.9756  0.797684   0.872093   0.600  0.710900"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seed 6171</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>0.799474</td>\n",
       "      <td>0.912121</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.725301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seed 2292</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.799158</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.720096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seed 4399</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.797789</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.712589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seed 8125</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>0.797053</td>\n",
       "      <td>0.889881</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.715311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seed 2492</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.797684</td>\n",
       "      <td>0.872093</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.710900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:55:52.819523Z",
     "start_time": "2024-06-07T02:55:52.811715Z"
    }
   },
   "cell_type": "code",
   "source": "lightGBM_new_b",
   "id": "58b2421963860127",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Seed  Accuracy       AUC  Precision  Recall  F1 Score\n",
       "0  Seed 6171    0.9771  0.807000   0.890490   0.618  0.729634\n",
       "1  Seed 2292    0.9760  0.796947   0.884615   0.598  0.713604\n",
       "2  Seed 4399    0.9761  0.803632   0.871795   0.612  0.719154\n",
       "3  Seed 8125    0.9749  0.786895   0.878419   0.578  0.697226\n",
       "4  Seed 2492    0.9737  0.782474   0.855856   0.570  0.684274"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seed 6171</td>\n",
       "      <td>0.9771</td>\n",
       "      <td>0.807000</td>\n",
       "      <td>0.890490</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.729634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seed 2292</td>\n",
       "      <td>0.9760</td>\n",
       "      <td>0.796947</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.713604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seed 4399</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.803632</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.719154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seed 8125</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0.786895</td>\n",
       "      <td>0.878419</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.697226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seed 2492</td>\n",
       "      <td>0.9737</td>\n",
       "      <td>0.782474</td>\n",
       "      <td>0.855856</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.684274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Permutation result compare",
   "id": "978c969ff775154f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:55:52.824076Z",
     "start_time": "2024-06-07T02:55:52.820535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "flattened_results = []\n",
    "for seed, data in results_p.items():\n",
    "    row = {\n",
    "        'Seed': seed,\n",
    "        'Accuracy': data['Accuracy'],\n",
    "        'AUC': data['AUC'],\n",
    "        'Precision': data['Precision'],\n",
    "        'Recall': data['Recall'],\n",
    "        'F1 Score': data['F1 Score']\n",
    "    }\n",
    "    flattened_results.append(row)\n",
    "\n",
    "## Create a DataFrame from the flattened dictionary\n",
    "lightGBM_p = pd.DataFrame(flattened_results)"
   ],
   "id": "31d7409e44522b82",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:55:52.829222Z",
     "start_time": "2024-06-07T02:55:52.825086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "flattened_results = []\n",
    "for seed, data in result_new_p.items():\n",
    "    row = {\n",
    "        'Seed': seed,\n",
    "        'Accuracy': data['Accuracy'],\n",
    "        'AUC': data['AUC'],\n",
    "        'Precision': data['Precision'],\n",
    "        'Recall': data['Recall'],\n",
    "        'F1 Score': data['F1 Score']\n",
    "    }\n",
    "    flattened_results.append(row)\n",
    "\n",
    "## Create a DataFrame from the flattened dictionary\n",
    "lightGBM_new_p = pd.DataFrame(flattened_results)"
   ],
   "id": "861403422bb7cda9",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:55:52.836793Z",
     "start_time": "2024-06-07T02:55:52.830231Z"
    }
   },
   "cell_type": "code",
   "source": "lightGBM_p",
   "id": "876bb29ea4f7ffc8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Seed  Accuracy       AUC  Precision  Recall  F1 Score\n",
       "0  Seed 6171    0.9768  0.797368   0.906061   0.598  0.720482\n",
       "1  Seed 2292    0.9762  0.799895   0.883041   0.604  0.717340\n",
       "2  Seed 4399    0.9752  0.789895   0.879518   0.584  0.701923\n",
       "3  Seed 8125    0.9758  0.788316   0.900621   0.580  0.705596\n",
       "4  Seed 2492    0.9752  0.793684   0.870588   0.592  0.704762"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seed 6171</td>\n",
       "      <td>0.9768</td>\n",
       "      <td>0.797368</td>\n",
       "      <td>0.906061</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.720482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seed 2292</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>0.799895</td>\n",
       "      <td>0.883041</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.717340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seed 4399</td>\n",
       "      <td>0.9752</td>\n",
       "      <td>0.789895</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.701923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seed 8125</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.788316</td>\n",
       "      <td>0.900621</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.705596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seed 2492</td>\n",
       "      <td>0.9752</td>\n",
       "      <td>0.793684</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.704762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T02:55:52.845630Z",
     "start_time": "2024-06-07T02:55:52.836793Z"
    }
   },
   "cell_type": "code",
   "source": "lightGBM_new_p",
   "id": "d7161c8962b1bea0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Seed  Accuracy       AUC  Precision  Recall  F1 Score\n",
       "0  Seed 6171    0.9770  0.809789   0.881356   0.624  0.730679\n",
       "1  Seed 2292    0.9767  0.808684   0.876056   0.622  0.727485\n",
       "2  Seed 4399    0.9761  0.800789   0.878261   0.606  0.717160\n",
       "3  Seed 8125    0.9773  0.807105   0.895652   0.618  0.731361\n",
       "4  Seed 2492    0.9757  0.793000   0.885886   0.590  0.708283"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seed 6171</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.809789</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.730679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seed 2292</td>\n",
       "      <td>0.9767</td>\n",
       "      <td>0.808684</td>\n",
       "      <td>0.876056</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.727485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seed 4399</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.800789</td>\n",
       "      <td>0.878261</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.717160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seed 8125</td>\n",
       "      <td>0.9773</td>\n",
       "      <td>0.807105</td>\n",
       "      <td>0.895652</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.731361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seed 2492</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.793000</td>\n",
       "      <td>0.885886</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.708283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "XGboost",
   "id": "84b53e17b3db1968"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "import xgboost as xgb\n",
    "result = {}\n",
    "for rsd in sd:\n",
    "    ## Perform Undersampling to make the data more balanced\n",
    "    X_train, X_test, y_train, y_test, feature_names = resample_split(rsd)\n",
    "        \n",
    "    ## Create XGBoost DMatrix\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "        \n",
    "    # Define the parameters\n",
    "    params = {\n",
    "            'booster': 'gbtree',\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': ['logloss', 'error', 'auc'],\n",
    "            'max_depth': 6,\n",
    "            'learning_rate': 0.1,\n",
    "            'reg_alpha': 0.01,  # L1 regularization to avoid overfitting\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.9,\n",
    "            'verbosity': 0\n",
    "        }\n",
    "        \n",
    "    ## Train the model\n",
    "    model = xgb.train(params, dtrain, num_boost_round=3000, evals=[(dtrain, 'train')])\n",
    "        \n",
    "    ## Predict the model using the testing sets\n",
    "    y_pred = model.predict(dtest)\n",
    "    y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "    \n",
    "    ## Obtain the model performance metrics\n",
    "    accuracy, auc, precision, recall, f1 = cus_metrics(y_test, y_pred)\n",
    "\n",
    "    ## Get the top 20 feature importance\n",
    "    feature_importance = model.get_score(importance_type='gain')\n",
    "    feature_importance_dict = dict(zip(feature_names, feature_importance))\n",
    "    top20feat = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "    \n",
    "    ## Save the result\n",
    "    result[f\"Seed {rsd}\"] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Top 20 Important Features': top20feat\n",
    "    }\n",
    "    print('finish')"
   ],
   "id": "fab1ab3ee6178b33"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "flattened_results = []\n",
    "for seed, data in result.items():\n",
    "    row = {\n",
    "        'Seed': seed,\n",
    "        'Accuracy': data['Accuracy'],\n",
    "        'AUC': data['AUC'],\n",
    "        'Precision': data['Precision'],\n",
    "        'Recall': data['Recall'],\n",
    "        'F1 Score': data['F1 Score']\n",
    "    }\n",
    "    for i, (feat_name, feat_value) in enumerate(data['Top 20 Important Features']):\n",
    "        row[f'Top{i+1} Feature Name'] = feat_name\n",
    "        row[f'Top{i+1} Feature Value'] = feat_value\n",
    "    flattened_results.append(row)\n",
    "\n",
    "\n",
    "XGB_df = pd.DataFrame(flattened_results)"
   ],
   "id": "43f3a3a451d9afcf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "XGB_df.to_csv('XGB_result.csv', index=False)",
   "id": "bd59e85d1aa8e2cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "X_preprocessed = reduce_mem_usage(pd.read_csv('X_preprocessed'))\n",
    "y = reduce_mem_usage(pd.read_csv('y'))"
   ],
   "id": "d9e0bd91fea89d10"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "y = y.iloc[:, 1]",
   "id": "d853492963d94eca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Autoencoders\n",
    "These unsupervised deep learning models learn about efficient data representations by reconstructing input data. They can be trained on normal fraudulent data and will flag instances of high reconstruction errors as possible fraud. They are good for identifying new types of fraud and detecting subtle anomalies."
   ],
   "id": "436359a93f364a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "result = {}\n",
    "\n",
    "for rsd in sd:\n",
    "    ## Perform Undersampling to make the data more balanced\n",
    "    X_train, X_test, y_train, y_test, feature_names = resample_split(rsd)\n",
    "    \n",
    "    ## Normalize data\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    ## Autoencoder Model Definition\n",
    "    input_dim = X_train_scaled.shape[1]\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(14, activation='relu')(input_layer)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "    \n",
    "    ## Encoder Model\n",
    "    encoder = Model(inputs=input_layer, outputs=encoded)\n",
    "    \n",
    "    ## Compile the model\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "    # Compile the model with the defined optimizer\n",
    "    autoencoder.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    \n",
    "    ## Train the model\n",
    "    autoencoder.fit(X_train_scaled, X_train_scaled,\n",
    "                    epochs=100,\n",
    "                    batch_size=32,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_test_scaled, X_test_scaled),\n",
    "                    verbose=0)\n",
    "    \n",
    "    ## Encoding the test set to detect anomalies (fraud)\n",
    "    encoded_test = encoder.predict(X_test_scaled)\n",
    "    reconstructions = autoencoder.predict(X_test_scaled)\n",
    "    mse = np.mean(np.power(X_test_scaled - reconstructions, 2), axis=1)\n",
    "    mse_threshold = np.percentile(mse, 95)  # Threshold for anomaly detection\n",
    "    y_pred = (mse > mse_threshold).astype(int)\n",
    "    \n",
    "    ## Obtain the model performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    ## Save the result\n",
    "    result[f\"Seed {rsd}\"] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC': auc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    }\n",
    "    print('Finished Seed:', rsd)\n"
   ],
   "id": "ee2d9bc553b932a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "flattened_results = []\n",
    "for seed, data in result.items():\n",
    "    row = {\n",
    "        'Seed': seed,\n",
    "        'Accuracy': data['Accuracy'],\n",
    "        'AUC': data['AUC'],\n",
    "        'Precision': data['Precision'],\n",
    "        'Recall': data['Recall'],\n",
    "        'F1 Score': data['F1 Score']\n",
    "    }\n",
    "    flattened_results.append(row)\n",
    "\n",
    "\n",
    "## Create a DataFrame from the flattened dictionary\n",
    "autoencoder_result = pd.DataFrame(flattened_results)"
   ],
   "id": "56b26f341ff2ea6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "autoencoder_result",
   "id": "4ed32c6e4b78ace",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "autoencoder_result.to_csv('autoencoder_result.csv', index=False)",
   "id": "8f1db788b7c81f28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1d59ec0f319f7c99",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
